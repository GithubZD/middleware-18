
## 1.开源项目分析 （node-soap）

+ ### 项目源码

  https://github.com/CongWeilin/mtcnn-caffe

+ ## mtcnn背景分析

  + **mtcnn**：算法是用来同时实现人脸检测和对齐。
              该算法的cascaded structure 主要包含三个子网络：Proposal Network(P-Net)、Refine Network(R-Net)、Output Network(O-Net)
              右图一开始对图像做了multi scale的Resize，构成了图像金字塔，然后这些不同scale的图像作为3个stage的输入进行训练，目的是为了可以检测不同scale的人脸。
              P-Net主要用来生成一些候选框.
              R-Net主要对P-Net的候选框进行提取，去除大量的非人脸框.
              O-Net和R-Net有点像，只不过这一步还增加了特征点位置的回归
  + **mtcnn theory**：
              P-Net利用全卷积网络，在不同的scale下采用12X12的滑块滑动窗口，以检测不同scale的人脸，得到每个滑块区域的得分，最大可能的粗略的得到人脸框的位置，经过R-Net对P-Net的候选框位置进行提取缩放为24X24的框图。O-Net把R-Net提取的框缩放为48X48的框图，加上特征点的检测的48X48的框图。
  + **train sample**  WIDERFACE：用于人脸的检测分类和回归训练数据，根据数据集标注，对目标区域做增强，平移、缩放等变换得到裁剪区域；
                      得到三类训练样本，即：正样本、负样本、部分(part)样本.
                      正样本：IoU >= 0.65，标签为1
                      负样本：IoU < 0.3，标签为0
                      部分(part)样本：0.65 > IoU >= 0.4，标签为-1
                      三个类的图片数量比例为3:1:1.然后把数据转换成imdb的格式.
                      其中IoU 为目标区域和裁剪区域的重合度。
                      celebA：用于特征点的检测，用github上训练好的模型切图片resize成48X48的图片，根据注释标出人脸特征点相对位置,然后把数据转换成imdb的格式.
                      正样本：	48/positive/0    1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
                      负样本：	48/negative/0   0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
                      正样本：	48/positive/0   -1 0.x 0.x 0.x 0.x -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
                      部分样本：	48/part/0 	    -1 0.x 0.x 0.x 0.x -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
                      特征点样本：48/landmark/0 -1 -1 -1 -1 -1 x 0.x 0.x 0.x 0.x 0.x 0.x
                      label != -1 做分类训练
                      roi[:,0] != -1 做回归训练
                      landmark[:,0] != -1 做特征点训练


+ ## mtcnn源码分析

  + ### 源码目录结构，如下所示

    ```
    .
    |____demo
    | |____12net.caffemodel
    | |____48net.caffemodel
    | |____24net.prototxt
    | |____48net.prototxt
    | |____tools.py
    | |____result.jpg
    | |____test.py
    | |____tools_matrix.py
    | |____24net.caffemodel
    | |____12net.prototxt
    |____24net
    | |____24net.prototxt
    | |____runcaffe.sh
    | |____pythonLayer.py
    | |____24net.caffemodel
    | |____solver.prototxt
    | |____train24.png
    | |____train24.prototxt
    | |____24net-only-cls.caffemodel
    |____README.md
    |____prepare_data
    | |____WIDER_train
    | | |____README.md
    | |____wider_face_train.txt
    | |____gen_24net_data.py
    | |____gen_net_imdb.py
    | |____gen_24net_hard_example.py
    | |____gen_12net_hard_example.py
    | |____utils.py
    | |____gen_12net_data.py
    | |____gen_48net_data.py
    |____.gitignore
    |_____config.yml
    |____12net
    | |____train12.png
    | |____12net.caffemodel
    | |____12net-cls-only.caffemodel
    | |____train12.prototxt
    | |____runcaffe.sh
    | |____pythonLayer.py
    | |____solver.prototxt
    | |____12net.prototxt
    |____48net
    | |____48net.caffemodel
    | |____48net.prototxt
    | |____48net-only-cls.caffemodel
    | |____train48.png
    | |____train48.prototxt
    | |____runcaffe.sh
    | |____pythonLayer.py
    | |____solver.prototxt

    ```

  + ### 生成训练样本的具体实现

    ```python
    f1 = open(os.path.join(save_dir, 'pos_12.txt'), 'w')
    f2 = open(os.path.join(save_dir, 'neg_12.txt'), 'w')
    f3 = open(os.path.join(save_dir, 'part_12.txt'), 'w')
    with open(anno_file, 'r') as f:
        annotations = f.readlines()
    num = len(annotations)
    print "%d pics in total" % num
    p_idx = 0 # positive
    n_idx = 0 # negative
    d_idx = 0 # dont care
    idx = 0
    box_idx = 0
    for annotation in annotations:
        annotation = annotation.strip().split(' ')
        im_path = annotation[0]
        bbox = map(float, annotation[1:]) 
        boxes = np.array(bbox, dtype=np.float32).reshape(-1, 4)
        img = cv2.imread(os.path.join(im_dir, im_path + '.jpg'))
        idx += 1
        if idx % 100 == 0:
            print idx, "images done"

        height, width, channel = img.shape

        neg_num = 0
        while neg_num < 50:
            size = npr.randint(40, min(width, height) / 2)
            nx = npr.randint(0, width - size)
            ny = npr.randint(0, height - size)
            crop_box = np.array([nx, ny, nx + size, ny + size])

            Iou = IoU(crop_box, boxes)

            cropped_im = img[ny : ny + size, nx : nx + size, :]
            resized_im = cv2.resize(cropped_im, (12, 12), interpolation=cv2.INTER_LINEAR)

            if np.max(Iou) < 0.3:
                # Iou with all gts must below 0.3
                save_file = os.path.join(neg_save_dir, "%s.jpg"%n_idx)
                f2.write("12/negative/%s"%n_idx + ' 0\n')
                cv2.imwrite(save_file, resized_im)
                n_idx += 1
                neg_num += 1
        for box in boxes:
            # box (x_left, y_top, x_right, y_bottom)
            x1, y1, x2, y2 = box
            w = x2 - x1 + 1
            h = y2 - y1 + 1

            # ignore small faces
            # in case the ground truth boxes of small faces are not accurate
            if max(w, h) < 40 or x1 < 0 or y1 < 0:
                continue

            # generate positive examples and part faces
            for i in range(20):
                size = npr.randint(int(min(w, h) * 0.8), np.ceil(1.25 * max(w, h)))

                # delta here is the offset of box center
                delta_x = npr.randint(-w * 0.2, w * 0.2)
                delta_y = npr.randint(-h * 0.2, h * 0.2)

                nx1 = max(x1 + w / 2 + delta_x - size / 2, 0)
                ny1 = max(y1 + h / 2 + delta_y - size / 2, 0)
                nx2 = nx1 + size
                ny2 = ny1 + size

                if nx2 > width or ny2 > height:
                    continue
                crop_box = np.array([nx1, ny1, nx2, ny2])

                offset_x1 = (x1 - nx1) / float(size)
                offset_y1 = (y1 - ny1) / float(size)
                offset_x2 = (x2 - nx2) / float(size)
                offset_y2 = (y2 - ny2) / float(size)

                cropped_im = img[int(ny1) : int(ny2), int(nx1) : int(nx2), :]
                resized_im = cv2.resize(cropped_im, (12, 12), interpolation=cv2.INTER_LINEAR)

                box_ = box.reshape(1, -1)
                if IoU(crop_box, box_) >= 0.65:
                    save_file = os.path.join(pos_save_dir, "%s.jpg"%p_idx)
                    f1.write("12/positive/%s"%p_idx + ' 1 %.2f %.2f %.2f %.2f\n'%(offset_x1, offset_y1, offset_x2, offset_y2))
                    cv2.imwrite(save_file, resized_im)
                    p_idx += 1
                elif IoU(crop_box, box_) >= 0.4:
                    save_file = os.path.join(part_save_dir, "%s.jpg"%d_idx)
                    f3.write("12/part/%s"%d_idx + ' -1 %.2f %.2f %.2f %.2f\n'%(offset_x1, offset_y1, offset_x2, offset_y2))
                    cv2.imwrite(save_file, resized_im)
                    d_idx += 1
            box_idx += 1
            print "%s images done, pos: %s part: %s neg: %s"%(idx, p_idx, d_idx, n_idx)

    f1.close()
    f2.close()
    f3.close()
    ```
  + ### caffe进行训练
    重点：采用pythonLayer层处理数据；
          class regression_Layer(caffe.Layer):
              def setup(self,bottom,top):
                  if len(bottom) != 2:
                      raise Exception("Need 2 Inputs")
              def reshape(self,bottom,top):
                  if bottom[0].count != bottom[1].count:
                      raise Exception("Input predict and groundTruth should have same dimension")
                  roi = bottom[1].data
                  self.valid_index = np.where(roi[:,0] != -1)[0]
                  self.N = len(self.valid_index)
                  self.diff = np.zeros_like(bottom[0].data, dtype=np.float32)
                  top[0].reshape(1)

              def forward(self,bottom,top):
                  self.diff[...] = 0
                  top[0].data[...] = 0
                  if self.N != 0:
                      self.diff[...] = bottom[0].data - np.array(bottom[1].data).reshape(bottom[0].data.shape)
                      top[0].data[...] = np.sum(self.diff**2) / bottom[0].num / 2.

              def backward(self,top,propagate_down,bottom):
                  for i in range(2):
                      if not propagate_down[i] or self.N==0:
                          continue
                      if i == 0:
                          sign = 1
                      else:
                          sign = -1
                      bottom[i].diff[...] = sign * self.diff / bottom[i].num
  + ### inference的构建

    ```python
    
    deploy = '12net.prototxt'
    caffemodel = '12net.caffemodel'
    net_12 = caffe.Net(deploy,caffemodel,caffe.TEST)

    deploy = '24net.prototxt'
    caffemodel = '24net.caffemodel'
    net_24 = caffe.Net(deploy,caffemodel,caffe.TEST)

    deploy = '48net.prototxt'
    caffemodel = '48net.caffemodel'
    net_48 = caffe.Net(deploy,caffemodel,caffe.TEST)


    def detectFace(img_path,threshold):
        img = cv2.imread(img_path)
        caffe_img = (img.copy()-127.5)/128
        origin_h,origin_w,ch = caffe_img.shape
        scales = tools.calculateScales(img)
        out = []
        for scale in scales:
            hs = int(origin_h*scale)
            ws = int(origin_w*scale)
            scale_img = cv2.resize(caffe_img,(ws,hs))
            scale_img = np.swapaxes(scale_img, 0, 2)
            net_12.blobs['data'].reshape(1,3,ws,hs)
            net_12.blobs['data'].data[...]=scale_img
      caffe.set_device(0)
      caffe.set_mode_gpu()
      out_ = net_12.forward()
            out.append(out_)
        image_num = len(scales)
        rectangles = []
        for i in range(image_num):    
            cls_prob = out[i]['prob1'][0][1]
            roi      = out[i]['conv4-2'][0]
            out_h,out_w = cls_prob.shape
            out_side = max(out_h,out_w)
            rectangle = tools.detect_face_12net(cls_prob,roi,out_side,1/scales[i],origin_w,origin_h,threshold[0])
            rectangles.extend(rectangle)
        rectangles = tools.NMS(rectangles,0.7,'iou')

        if len(rectangles)==0:
            return rectangles
        net_24.blobs['data'].reshape(len(rectangles),3,24,24)
        crop_number = 0
        for rectangle in rectangles:
            crop_img = caffe_img[int(rectangle[1]):int(rectangle[3]), int(rectangle[0]):int(rectangle[2])]
            scale_img = cv2.resize(crop_img,(24,24))
            scale_img = np.swapaxes(scale_img, 0, 2)
            net_24.blobs['data'].data[crop_number] =scale_img 
            crop_number += 1
        out = net_24.forward()
        cls_prob = out['prob1']
        roi_prob = out['conv5-2']
        rectangles = tools.filter_face_24net(cls_prob,roi_prob,rectangles,origin_w,origin_h,threshold[1])
        
        if len(rectangles)==0:
            return rectangles
        net_48.blobs['data'].reshape(len(rectangles),3,48,48)
        crop_number = 0
        for rectangle in rectangles:
            crop_img = caffe_img[int(rectangle[1]):int(rectangle[3]), int(rectangle[0]):int(rectangle[2])]
            scale_img = cv2.resize(crop_img,(48,48))
            scale_img = np.swapaxes(scale_img, 0, 2)
            net_48.blobs['data'].data[crop_number] =scale_img 
            crop_number += 1
        out = net_48.forward()
        cls_prob = out['prob1']
        roi_prob = out['conv6-2']
        pts_prob = out['conv6-3']
        rectangles = tools.filter_face_48net(cls_prob,roi_prob,pts_prob,rectangles,origin_w,origin_h,threshold[2])

        return rectangles

    threshold = [0.6,0.6,0.7]
    imgpath = ""
    rectangles = detectFace(imgpath,threshold)
    img = cv2.imread(imgpath)
    draw = img.copy()
    for rectangle in rectangles:
        cv2.putText(draw,str(rectangle[4]),(int(rectangle[0]),int(rectangle[1])),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0))
        cv2.rectangle(draw,(int(rectangle[0]),int(rectangle[1])),(int(rectangle[2]),int(rectangle[3])),(255,0,0),1)
        for i in range(5,15,2):
          cv2.circle(draw,(int(rectangle[i+0]),int(rectangle[i+1])),2,(0,255,0))
    cv2.imshow("test",draw)
    cv2.waitKey()
    cv2.imwrite('test.jpg',draw)

    ```


